{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5823d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domino\n",
    "from domino import embed\n",
    "from domino._embed.encoder import Encoder\n",
    "from domino import explore, DominoSlicer\n",
    "# Standard library imports\n",
    "import meerkat as mk\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Clip model \n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "from PIL import Image\n",
    "import random\n",
    "from meerkat import DataPanel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas() \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e8a73f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Finding\n",
       "1.0    75455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "# split the data into train and test sets by 0.8 and 0.2\n",
    "# train_df = data_df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "# test_df = data_df.drop(train_df.index).reset_index(drop=True)   \n",
    "# # Save the train and test DataFrames to CSV files\n",
    "# # train_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df.csv\", index=False)\n",
    "# # test_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df.csv\", index=False)\n",
    "# Load the train and test DataFrames\n",
    "\n",
    "# train_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df.csv\")\n",
    "# test_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df.csv\")\n",
    "\n",
    "data_df[\"No Finding\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340fe7fd",
   "metadata": {},
   "source": [
    "Train finding & cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c016e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3251480/2005903429.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_df[\"No Finding\"].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned on finding: (227827, 16)\n",
      " Cardiomegaly: Cardiomegaly\n",
      "1.0    35840\n",
      "0.0    12743\n",
      "Name: count, dtype: int64\n",
      " Cardiomegaly: Cardiomegaly\n",
      " 1.0    34884\n",
      " 0.0    12646\n",
      "-1.0     4740\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# All the No finding columns have been  set to 1 or 0\n",
    "# clean the data_df on finding\n",
    "# Fill null values in \"No Finding\" column with 0\n",
    "data_df[\"No Finding\"].fillna(0, inplace=True)\n",
    "data_df_cleaned_finding = data_df[data_df[\"No Finding\"].isin([1, 0])].reset_index(drop=True)\n",
    "#data_df_cleaned_finding = data_df_cleaned_finding[data_df_cleaned_finding[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "print(f\"Data cleaned on finding: {data_df_cleaned_finding.shape}\")\n",
    "# Split the data into train and test sets by 0.8 and 0.2\n",
    "train_df = data_df_cleaned_finding.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True).copy()\n",
    "test_df = data_df_cleaned_finding.drop(train_df.index).reset_index(drop=True)   \n",
    "# Save the train and test DataFrames to CSV files\n",
    "print(f\" Cardiomegaly: {train_df['Cardiomegaly'].value_counts()}\")\n",
    "print(f\" Cardiomegaly: {test_df['Cardiomegaly'].value_counts()}\")\n",
    "# flip the No Finding column to Finding column\n",
    "train_df['Finding'] = train_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Save the files \n",
    "train_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_findings_cardio.csv\", index=False)\n",
    "#test_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_findings_cardio.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a0dc559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10335334</td>\n",
       "      <td>56048989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13007347</td>\n",
       "      <td>51404713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16425412</td>\n",
       "      <td>58032996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15281216</td>\n",
       "      <td>59204145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17419409</td>\n",
       "      <td>54829080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0    10335334  56048989          1.0           0.0            NaN    0.0   \n",
       "1    13007347  51404713          NaN           0.0            NaN    NaN   \n",
       "2    16425412  58032996          1.0           0.0            NaN    NaN   \n",
       "3    15281216  59204145          1.0           1.0            NaN    NaN   \n",
       "4    17419409  54829080          NaN           0.0            NaN    0.0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         NaN       NaN          NaN           NaN   \n",
       "1                         NaN       NaN          NaN           NaN   \n",
       "2                         1.0       NaN          NaN           NaN   \n",
       "3                         NaN       NaN          NaN           1.0   \n",
       "4                         NaN       NaN          NaN           NaN   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0         0.0               NaN            NaN        0.0           NaN   \n",
       "1         1.0               0.0            NaN        NaN           0.0   \n",
       "2         0.0               NaN            NaN        0.0           NaN   \n",
       "3         0.0               1.0            NaN        NaN           NaN   \n",
       "4         1.0               0.0            NaN        0.0           NaN   \n",
       "\n",
       "   Support Devices  Finding  \n",
       "0              1.0        1  \n",
       "1              1.0        0  \n",
       "2              NaN        1  \n",
       "3              NaN        1  \n",
       "4              NaN        0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b84977",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_new = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/test_df_with_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf291054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3251480/363068135.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df_new['No Finding'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_3251480/363068135.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df_new['Cardiomegaly'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned on finding: (7946, 40)\n"
     ]
    }
   ],
   "source": [
    "test_df_new.head()\n",
    "test_df_new['No Finding'].fillna(0, inplace=True)\n",
    "test_df_new = test_df_new[test_df_new[\"No Finding\"].isin([1, 0])].reset_index(drop=True)\n",
    "test_df_new['Cardiomegaly'].value_counts()\n",
    "#len(test_df_new)\n",
    "# fill all cardiomegaly values if not 1 than set to 0\n",
    "test_df_new['Cardiomegaly'].fillna(0, inplace=True)\n",
    "test_df_new = test_df_new[test_df_new[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "print(f\"Data cleaned on finding: {test_df_new.shape}\")\n",
    "# Save the test DataFrame to CSV file\n",
    "#test_df_new.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_findings_cardio.csv\", index=False)\n",
    "test_df_new['Finding'] = test_df_new['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "test_df_new.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_with_embeddings_cardio.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabf647",
   "metadata": {},
   "source": [
    "Train No Finding & View Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c77de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "data_df[\"No Finding\"].fillna(0)\n",
    "data_df_cleaned_finding = data_df[data_df[\"No Finding\"].isin([1, 0])].reset_index(drop=True)\n",
    "meta_df = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/meta_df_processed.parquet\")\n",
    "\n",
    "# Merge the data_df_cleaned_finding to meta_df_processed on \"subject_id\" and \"study_id\"\n",
    "data_meta_df = pd.merge(data_df_cleaned_finding, meta_df, on=[\"subject_id\", \"study_id\"], how=\"right\")\n",
    "data_meta_df['view_position_text'].value_counts()\n",
    "train_df = data_meta_df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "# drop all the rows with view_position_text as \"standard view'\n",
    "train_df = train_df[train_df[\"view_position_text\"] != \"standard view\"].reset_index(drop=True)\n",
    "train_df['Position'] = [0 if 'lateral' in x else 1 for x in train_df['view_position_text']]\n",
    "train_df['Position'].value_counts()\n",
    "train_df['Finding'] = train_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "train_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_position.parquet\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65d57ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'study_id', 'Atelectasis', 'Cardiomegaly',\n",
       "       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture',\n",
       "       'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
       "       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices',\n",
       "       'dicom_id', 'PerformedProcedureStepDescription', 'ViewPosition', 'Rows',\n",
       "       'Columns', 'StudyDate', 'StudyTime',\n",
       "       'ProcedureCodeSequence_CodeMeaning', 'ViewCodeSequence_CodeMeaning',\n",
       "       'PatientOrientationCodeSequence_CodeMeaning', 'id', 'exam_type_text',\n",
       "       'view_position_text', 'patient_orientation_text', 'image_quality_text',\n",
       "       'study_time_text', 'metadata_description', 'Position', 'Finding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04a30dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>PerformedProcedureStepDescription</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>ProcedureCodeSequence_CodeMeaning</th>\n",
       "      <th>ViewCodeSequence_CodeMeaning</th>\n",
       "      <th>PatientOrientationCodeSequence_CodeMeaning</th>\n",
       "      <th>id</th>\n",
       "      <th>exam_type_text</th>\n",
       "      <th>view_position_text</th>\n",
       "      <th>patient_orientation_text</th>\n",
       "      <th>image_quality_text</th>\n",
       "      <th>study_time_text</th>\n",
       "      <th>metadata_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 50414267]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 50414267]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 53189527]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 53189527]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>2705</td>\n",
       "      <td>2539</td>\n",
       "      <td>21800723</td>\n",
       "      <td>80556.875</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>None</td>\n",
       "      <td>[10000032, 53911762]</td>\n",
       "      <td>bedside portable chest radiography</td>\n",
       "      <td>anterior-posterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>standard resolution</td>\n",
       "      <td>in July 2180 during night hours</td>\n",
       "      <td>Patient underwent bedside portable chest radio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  subject_id  study_id  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014    10000032  50414267   \n",
       "1  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962    10000032  50414267   \n",
       "2  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab    10000032  53189527   \n",
       "3  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c    10000032  53189527   \n",
       "4  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714    10000032  53911762   \n",
       "\n",
       "  PerformedProcedureStepDescription ViewPosition  Rows  Columns  StudyDate  \\\n",
       "0                CHEST (PA AND LAT)           PA  3056     2544   21800506   \n",
       "1                CHEST (PA AND LAT)      LATERAL  3056     2544   21800506   \n",
       "2                CHEST (PA AND LAT)           PA  3056     2544   21800626   \n",
       "3                CHEST (PA AND LAT)      LATERAL  3056     2544   21800626   \n",
       "4               CHEST (PORTABLE AP)           AP  2705     2539   21800723   \n",
       "\n",
       "    StudyTime ProcedureCodeSequence_CodeMeaning ViewCodeSequence_CodeMeaning  \\\n",
       "0  213014.531                CHEST (PA AND LAT)             postero-anterior   \n",
       "1  213014.531                CHEST (PA AND LAT)                      lateral   \n",
       "2  165500.312                CHEST (PA AND LAT)             postero-anterior   \n",
       "3  165500.312                CHEST (PA AND LAT)                      lateral   \n",
       "4   80556.875               CHEST (PORTABLE AP)             antero-posterior   \n",
       "\n",
       "  PatientOrientationCodeSequence_CodeMeaning                    id  \\\n",
       "0                                      Erect  [10000032, 50414267]   \n",
       "1                                      Erect  [10000032, 50414267]   \n",
       "2                                      Erect  [10000032, 53189527]   \n",
       "3                                      Erect  [10000032, 53189527]   \n",
       "4                                       None  [10000032, 53911762]   \n",
       "\n",
       "                       exam_type_text       view_position_text  \\\n",
       "0                   chest radiography  posterior-anterior view   \n",
       "1                   chest radiography             lateral view   \n",
       "2                   chest radiography  posterior-anterior view   \n",
       "3                   chest radiography             lateral view   \n",
       "4  bedside portable chest radiography  anterior-posterior view   \n",
       "\n",
       "  patient_orientation_text   image_quality_text  \\\n",
       "0         upright position      high-resolution   \n",
       "1         upright position      high-resolution   \n",
       "2         upright position      high-resolution   \n",
       "3         upright position      high-resolution   \n",
       "4         upright position  standard resolution   \n",
       "\n",
       "                       study_time_text  \\\n",
       "0     in May 2180 during evening hours   \n",
       "1     in May 2180 during evening hours   \n",
       "2  in June 2180 during afternoon hours   \n",
       "3  in June 2180 during afternoon hours   \n",
       "4      in July 2180 during night hours   \n",
       "\n",
       "                                metadata_description  \n",
       "0  Patient underwent chest radiography in May 218...  \n",
       "1  Patient underwent chest radiography in May 218...  \n",
       "2  Patient underwent chest radiography in June 21...  \n",
       "3  Patient underwent chest radiography in June 21...  \n",
       "4  Patient underwent bedside portable chest radio...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6303ea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'study_id', 'Atelectasis', 'Cardiomegaly',\n",
      "       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture',\n",
      "       'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
      "       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices',\n",
      "       'predicted', 'true', 'id_x', 'path', 'dicom_id_x',\n",
      "       'PerformedProcedureStepDescription_x', 'ViewPosition_x', 'Rows_x',\n",
      "       'Columns_x', 'StudyDate_x', 'StudyTime_x',\n",
      "       'ProcedureCodeSequence_CodeMeaning_x', 'ViewCodeSequence_CodeMeaning_x',\n",
      "       'PatientOrientationCodeSequence_CodeMeaning_x', 'exam_type_text_x',\n",
      "       'view_position_text_x', 'patient_orientation_text_x',\n",
      "       'image_quality_text_x', 'study_time_text_x', 'metadata_description_x',\n",
      "       'report_text', 'image_embedding', 'report_embedding',\n",
      "       'metadata_embedding', 'dicom_id_y',\n",
      "       'PerformedProcedureStepDescription_y', 'ViewPosition_y', 'Rows_y',\n",
      "       'Columns_y', 'StudyDate_y', 'StudyTime_y',\n",
      "       'ProcedureCodeSequence_CodeMeaning_y', 'ViewCodeSequence_CodeMeaning_y',\n",
      "       'PatientOrientationCodeSequence_CodeMeaning_y', 'id_y',\n",
      "       'exam_type_text_y', 'view_position_text_y',\n",
      "       'patient_orientation_text_y', 'image_quality_text_y',\n",
      "       'study_time_text_y', 'metadata_description_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_meta_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c270b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position\n",
      "1    7392\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Finding\n",
      "1    7523\n",
      "0     874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_df_new = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/test_df_with_embeddings.parquet\")\n",
    "\n",
    "\n",
    "test_df_new['No Finding'] = test_df_new['No Finding'].fillna(0)\n",
    "test_df_new = test_df_new[test_df_new['No Finding'].isin([0, 1])].reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "\n",
    "test_meta_df = test_df_new.copy()\n",
    "\n",
    "\n",
    "test_meta_df['Finding'] = test_meta_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "test_meta_df['Position'] = [0 if 'lateral' in x else 1 for x in test_meta_df['view_position_text']]\n",
    "\n",
    "print(test_meta_df['Position'].value_counts())\n",
    "print(test_meta_df['Finding'].value_counts())\n",
    "\n",
    "\n",
    "test_meta_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_position.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5723ae72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'study_id', 'Atelectasis', 'Cardiomegaly',\n",
       "       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture',\n",
       "       'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
       "       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices',\n",
       "       'predicted', 'true', 'id_x', 'path', 'dicom_id_x',\n",
       "       'PerformedProcedureStepDescription_x', 'ViewPosition_x', 'Rows_x',\n",
       "       'Columns_x', 'StudyDate_x', 'StudyTime_x',\n",
       "       'ProcedureCodeSequence_CodeMeaning_x', 'ViewCodeSequence_CodeMeaning_x',\n",
       "       'PatientOrientationCodeSequence_CodeMeaning_x', 'exam_type_text_x',\n",
       "       'view_position_text_x', 'patient_orientation_text_x',\n",
       "       'image_quality_text_x', 'study_time_text_x', 'metadata_description_x',\n",
       "       'report_text', 'image_embedding', 'report_embedding',\n",
       "       'metadata_embedding', 'dicom_id_y',\n",
       "       'PerformedProcedureStepDescription_y', 'ViewPosition_y', 'Rows_y',\n",
       "       'Columns_y', 'StudyDate_y', 'StudyTime_y',\n",
       "       'ProcedureCodeSequence_CodeMeaning_y', 'ViewCodeSequence_CodeMeaning_y',\n",
       "       'PatientOrientationCodeSequence_CodeMeaning_y', 'id_y',\n",
       "       'exam_type_text_y', 'view_position_text_y',\n",
       "       'patient_orientation_text_y', 'image_quality_text_y',\n",
       "       'study_time_text_y', 'metadata_description_y', 'Position', 'Finding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20907f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Position\n",
       "1    64965\n",
       "0    45001\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafdae8",
   "metadata": {},
   "source": [
    "### Metadata Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c3f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-metadata.csv\")\n",
    "meta_df['id'] = list(zip(meta_df['subject_id'].astype(str), \n",
    "                            meta_df['study_id'].astype(str))) \n",
    "# Convert the information to the text format \n",
    "meta_df_processed = convert_medical_metadata_to_text(meta_df)  \n",
    "meta_df_processed.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/meta_df_processed.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26620a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>PerformedProcedureStepDescription</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>ProcedureCodeSequence_CodeMeaning</th>\n",
       "      <th>ViewCodeSequence_CodeMeaning</th>\n",
       "      <th>PatientOrientationCodeSequence_CodeMeaning</th>\n",
       "      <th>id</th>\n",
       "      <th>exam_type_text</th>\n",
       "      <th>view_position_text</th>\n",
       "      <th>patient_orientation_text</th>\n",
       "      <th>image_quality_text</th>\n",
       "      <th>study_time_text</th>\n",
       "      <th>metadata_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 50414267)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 50414267)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 53189527)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 53189527)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>2705</td>\n",
       "      <td>2539</td>\n",
       "      <td>21800723</td>\n",
       "      <td>80556.875</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(10000032, 53911762)</td>\n",
       "      <td>bedside portable chest radiography</td>\n",
       "      <td>anterior-posterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>standard resolution</td>\n",
       "      <td>in July 2180 during night hours</td>\n",
       "      <td>Patient underwent bedside portable chest radio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  subject_id  study_id  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014    10000032  50414267   \n",
       "1  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962    10000032  50414267   \n",
       "2  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab    10000032  53189527   \n",
       "3  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c    10000032  53189527   \n",
       "4  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714    10000032  53911762   \n",
       "\n",
       "  PerformedProcedureStepDescription ViewPosition  Rows  Columns  StudyDate  \\\n",
       "0                CHEST (PA AND LAT)           PA  3056     2544   21800506   \n",
       "1                CHEST (PA AND LAT)      LATERAL  3056     2544   21800506   \n",
       "2                CHEST (PA AND LAT)           PA  3056     2544   21800626   \n",
       "3                CHEST (PA AND LAT)      LATERAL  3056     2544   21800626   \n",
       "4               CHEST (PORTABLE AP)           AP  2705     2539   21800723   \n",
       "\n",
       "    StudyTime ProcedureCodeSequence_CodeMeaning ViewCodeSequence_CodeMeaning  \\\n",
       "0  213014.531                CHEST (PA AND LAT)             postero-anterior   \n",
       "1  213014.531                CHEST (PA AND LAT)                      lateral   \n",
       "2  165500.312                CHEST (PA AND LAT)             postero-anterior   \n",
       "3  165500.312                CHEST (PA AND LAT)                      lateral   \n",
       "4   80556.875               CHEST (PORTABLE AP)             antero-posterior   \n",
       "\n",
       "  PatientOrientationCodeSequence_CodeMeaning                    id  \\\n",
       "0                                      Erect  (10000032, 50414267)   \n",
       "1                                      Erect  (10000032, 50414267)   \n",
       "2                                      Erect  (10000032, 53189527)   \n",
       "3                                      Erect  (10000032, 53189527)   \n",
       "4                                        NaN  (10000032, 53911762)   \n",
       "\n",
       "                       exam_type_text       view_position_text  \\\n",
       "0                   chest radiography  posterior-anterior view   \n",
       "1                   chest radiography             lateral view   \n",
       "2                   chest radiography  posterior-anterior view   \n",
       "3                   chest radiography             lateral view   \n",
       "4  bedside portable chest radiography  anterior-posterior view   \n",
       "\n",
       "  patient_orientation_text   image_quality_text  \\\n",
       "0         upright position      high-resolution   \n",
       "1         upright position      high-resolution   \n",
       "2         upright position      high-resolution   \n",
       "3         upright position      high-resolution   \n",
       "4         upright position  standard resolution   \n",
       "\n",
       "                       study_time_text  \\\n",
       "0     in May 2180 during evening hours   \n",
       "1     in May 2180 during evening hours   \n",
       "2  in June 2180 during afternoon hours   \n",
       "3  in June 2180 during afternoon hours   \n",
       "4      in July 2180 during night hours   \n",
       "\n",
       "                                metadata_description  \n",
       "0  Patient underwent chest radiography in May 218...  \n",
       "1  Patient underwent chest radiography in May 218...  \n",
       "2  Patient underwent chest radiography in June 21...  \n",
       "3  Patient underwent chest radiography in June 21...  \n",
       "4  Patient underwent bedside portable chest radio...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a176e8",
   "metadata": {},
   "source": [
    "### Metadata Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99db94e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_position_text\n",
       "anterior-posterior view        147173\n",
       "lateral view                   117986\n",
       "posterior-anterior view         96161\n",
       "standard view                   15784\n",
       "left anterior oblique view          3\n",
       "right anterior oblique view         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_processed.head()\n",
    "meta_df_processed[\"view_position_text\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a9be0",
   "metadata": {},
   "source": [
    "### Test Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504d1a4",
   "metadata": {},
   "source": [
    "Report Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2dd75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10543/10543 [00:12<00:00, 843.08it/s] \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "REPORTS_DIR = \"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/files/mimic_reports/\"\n",
    "\n",
    "def read_mimic_report(subject_id, study_id):\n",
    "    subject_dir = f\"p{str(subject_id)[:2]}\"\n",
    "    subject_full = f\"p{subject_id}\"\n",
    "    report_file = f\"s{study_id}.txt\"\n",
    "    file_path = os.path.join(REPORTS_DIR, 'files', subject_dir, subject_full, report_file)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "\n",
    "test_df['report_text'] = test_df.progress_apply(\n",
    "    lambda row: read_mimic_report(row['subject_id'], row['study_id']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aadd9324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing paths: 1356\n",
      "Number of missing metadata descriptions: 0\n",
      "length of test_df: 9187\n"
     ]
    }
   ],
   "source": [
    "# import the path file\n",
    "path = pickle.load(open('file_map_cache_complete.pkl', 'rb'))\n",
    "\n",
    "# convert the path to a DataFrame\n",
    "test_df['id'] = list(zip(test_df['subject_id'].astype(str), \n",
    "                         test_df['study_id'].astype(str)))\n",
    "path_images = [k[0] for k in path.values()]\n",
    "path_df = pd.DataFrame({\"id\": list(path.keys()), \"path\": path_images})\n",
    "test_df = pd.merge(test_df, path_df, on='id', how='left')\n",
    "\n",
    "# find the id without a path\n",
    "missing_paths = test_df[test_df['path'].isnull()]['id'].tolist()\n",
    "print(f\"Number of missing paths: {len(missing_paths)}\")\n",
    "\n",
    "\n",
    "test_df = test_df[test_df['path'].notnull()].copy()\n",
    "\n",
    "# extract dicom_id from path safely\n",
    "test_df[\"dicom_id\"] = test_df[\"path\"].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "\n",
    "# merge the test_df with the metadata\n",
    "test_df = pd.merge(test_df, meta_df_processed, on='dicom_id', how='left')\n",
    "\n",
    "# find the id without a metadata description\n",
    "missing_metadata = test_df[test_df['metadata_description'].isnull()]['dicom_id'].tolist()\n",
    "print(f\"Number of missing metadata descriptions: {len(missing_metadata)}\")\n",
    "\n",
    "print(\"length of test_df:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687a09b",
   "metadata": {},
   "source": [
    "### Extract Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65040ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding for the images and report text\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
    ")\n",
    "tokenizer = get_tokenizer(\n",
    "    'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device).eval()\n",
    "\n",
    "# define Transform which resize the image to 224x224 and normalize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(           \n",
    "        mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "        std=[0.26862954, 0.26130258, 0.27577711]\n",
    "    )\n",
    "])\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    tokenized = tokenizer([text]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(tokenized)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)  \n",
    "    return text_features[0].cpu().numpy() # Add batch dimension for consistency\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "\n",
    "    image_tensor = preprocess(image).unsqueeze(0).to(device) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        image_features = model.encode_image(image_tensor)\n",
    "\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    return image_features[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['image_embedding'] = test_df['path'].progress_apply(get_image_embedding)\n",
    "test_df[\"report_embedding\"] = test_df['report_text'].progress_apply(get_text_embedding)\n",
    "test_df[\"metadata_embedding\"] = test_df['metadata_description'].progress_apply(get_text_embedding)\n",
    "test_df.to_parquet('test_df_with_embeddings_v2.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e894d568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15517908</td>\n",
       "      <td>54944476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14997223</td>\n",
       "      <td>56919551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15831913</td>\n",
       "      <td>55952386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18994929</td>\n",
       "      <td>53818785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12868814</td>\n",
       "      <td>58575191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42166</th>\n",
       "      <td>14325424</td>\n",
       "      <td>58251915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42167</th>\n",
       "      <td>13295971</td>\n",
       "      <td>50868944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42168</th>\n",
       "      <td>18527164</td>\n",
       "      <td>50617229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42169</th>\n",
       "      <td>16898052</td>\n",
       "      <td>54026371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42170</th>\n",
       "      <td>15247151</td>\n",
       "      <td>59516241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42171 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0        15517908  54944476          1.0           1.0            NaN   -1.0   \n",
       "1        14997223  56919551          1.0           1.0            NaN    NaN   \n",
       "2        15831913  55952386          NaN           NaN            NaN    NaN   \n",
       "3        18994929  53818785          1.0           NaN            NaN    NaN   \n",
       "4        12868814  58575191          NaN           1.0            NaN   -1.0   \n",
       "...           ...       ...          ...           ...            ...    ...   \n",
       "42166    14325424  58251915          NaN           NaN            1.0    NaN   \n",
       "42167    13295971  50868944          1.0           NaN            NaN    0.0   \n",
       "42168    18527164  50617229          1.0           NaN            NaN    NaN   \n",
       "42169    16898052  54026371          1.0           NaN            NaN    NaN   \n",
       "42170    15247151  59516241          1.0           0.0            NaN    NaN   \n",
       "\n",
       "       Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                             NaN       1.0          NaN           1.0   \n",
       "1                            -1.0       NaN          NaN           NaN   \n",
       "2                             NaN       NaN          NaN           NaN   \n",
       "3                             NaN       NaN          NaN           NaN   \n",
       "4                             NaN       NaN          NaN           1.0   \n",
       "...                           ...       ...          ...           ...   \n",
       "42166                        -1.0       NaN          NaN           1.0   \n",
       "42167                         NaN       NaN          NaN           NaN   \n",
       "42168                         NaN       NaN          NaN           1.0   \n",
       "42169                         NaN       NaN          NaN           NaN   \n",
       "42170                         NaN       NaN          NaN           NaN   \n",
       "\n",
       "       No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0             NaN               1.0            NaN        NaN           0.0   \n",
       "1             NaN               1.0            NaN        NaN           0.0   \n",
       "2             NaN               1.0            NaN        NaN           0.0   \n",
       "3             NaN               NaN            NaN        NaN           0.0   \n",
       "4             NaN               1.0            NaN        NaN           1.0   \n",
       "...           ...               ...            ...        ...           ...   \n",
       "42166         NaN               1.0            NaN        NaN           1.0   \n",
       "42167         NaN               0.0            NaN        NaN           0.0   \n",
       "42168         NaN               1.0            NaN        NaN           0.0   \n",
       "42169         NaN               NaN            NaN        NaN           0.0   \n",
       "42170         NaN               NaN            NaN        NaN           0.0   \n",
       "\n",
       "       Support Devices  \n",
       "0                  NaN  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "...                ...  \n",
       "42166              1.0  \n",
       "42167              1.0  \n",
       "42168              1.0  \n",
       "42169              1.0  \n",
       "42170              NaN  \n",
       "\n",
       "[42171 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d2e57",
   "metadata": {},
   "source": [
    "### Train data set for meta classifiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df = train_df.merge(\n",
    "    meta_df_processed[['subject_id', 'study_id', 'exam_type_text']],\n",
    "    on=['subject_id', 'study_id'],\n",
    "    how='left'\n",
    ")\n",
    "train_meta_df['is_portable'] = train_meta_df['exam_type_text']\\\n",
    "    .str.contains('portable', case=False, na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2d0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 1,0\n",
    "train_meta_df['is_portable'] = train_meta_df['is_portable'].astype(int)\n",
    "\n",
    "# test set \n",
    "test_df = pd.read_parquet('test_df_with_embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6371055",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta_df = test_df.copy()\n",
    "test_meta_df['is_portable'] = test_meta_df['exam_type_text']\\\n",
    "    .str.contains('portable', case=False, na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f060dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train meta DataFrame shape: (25239, 18)\n",
      "Cardiomegaly\n",
      "1.0    16597\n",
      "0.0     8642\n",
      "Name: count, dtype: int64\n",
      "Test meta DataFrame shape: (3701, 41)\n",
      "Cardiomegaly\n",
      "1.0    2505\n",
      "0.0    1196\n",
      "Name: count, dtype: int64\n",
      "Train meta DataFrame is_portable value counts:\n",
      "is_portable\n",
      "1    16016\n",
      "0     9223\n",
      "Name: count, dtype: int64\n",
      "Test meta DataFrame is_portable value counts:\n",
      "is_portable\n",
      "True     2835\n",
      "False     866\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_meta_df = train_meta_df[train_meta_df['Cardiomegaly'].isin([0, 1])]\n",
    "print(\"Train meta DataFrame shape:\", train_meta_df.shape)\n",
    "# value counts for Cardiomegaly\n",
    "print(train_meta_df['Cardiomegaly'].value_counts())\n",
    "test_meta_df = test_meta_df[test_meta_df['Cardiomegaly'].isin([0, 1])]\n",
    "print(\"Test meta DataFrame shape:\", test_meta_df.shape)\n",
    "# value counts for Cardiomegaly\n",
    "print(test_meta_df['Cardiomegaly'].value_counts())\n",
    "# for portable value counts\n",
    "print(\"Train meta DataFrame is_portable value counts:\")\n",
    "print(train_meta_df['is_portable'].value_counts())\n",
    "print(\"Test meta DataFrame is_portable value counts:\")\n",
    "print(test_meta_df['is_portable'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a721e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test dataframes with meta embeddings \n",
    "train_meta_df.to_parquet('train_meta_df_with_embeddings.parquet', index=False)\n",
    "test_meta_df.to_parquet('test_meta_df_with_embeddings.parquet', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc36c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1614328/2254601363.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_df[\"Cardiomegaly\"].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cardiomegaly\n",
       "0.0    233213\n",
       "1.0     49289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "#data_df[\"No Finding\"].fillna(0)\n",
    "data_df[\"Cardiomegaly\"].fillna(0, inplace=True)\n",
    "data_df_cleaned_finding = data_df[data_df[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "meta_df = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/meta_df_processed.parquet\")\n",
    "\n",
    "# Merge the data_df_cleaned_finding to meta_df_processed on \"subject_id\" and \"study_id\"\n",
    "data_meta_df = pd.merge(data_df_cleaned_finding, meta_df, on=[\"subject_id\", \"study_id\"], how=\"right\")\n",
    "data_meta_df['view_position_text'].value_counts()\n",
    "train_df = data_meta_df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "# drop all the rows with view_position_text as \"standard view'\n",
    "train_df = train_df[train_df[\"view_position_text\"] != \"standard view\"].reset_index(drop=True)\n",
    "train_df['Position'] = [0 if 'lateral' in x else 1 for x in train_df['view_position_text']]\n",
    "train_df['Cardiomegaly'].value_counts()\n",
    "\n",
    "#train_df['Finding'] = train_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "#train_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_position.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31f8c93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81978</td>\n",
       "      <td>11157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151235</td>\n",
       "      <td>38132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cardiomegaly     0.0    1.0\n",
       "Position                   \n",
       "0              81978  11157\n",
       "1             151235  38132"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_results.groupby(['Position', 'true']).size().unstack(fill_value=0)\n",
    "train_df.groupby(['Position', 'Cardiomegaly']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c56df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train and test dataframes with meta embeddings\n",
    "test_df = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_position.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4982865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1614328/3084683551.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Cardiomegaly'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4709</td>\n",
       "      <td>2289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cardiomegaly   0.0   1.0\n",
       "Position                \n",
       "0              732   216\n",
       "1             4709  2289"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Cardiomegaly'].fillna(0, inplace=True)\n",
    "test_df = test_df[test_df[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "test_df.groupby(['Position', 'Cardiomegaly']).size().unstack(fill_value=0)\n",
    "# Save the test DataFrame to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "484acaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes with embeddings\n",
    "test_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_with_embeddings_cardio_position.parquet\", index=False)\n",
    "train_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_cardio_position.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b0049",
   "metadata": {},
   "source": [
    "### Create the embedding use clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e035ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test_df_with_embeddings.parquet')\n",
    "train_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7359982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    inputs = processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**inputs)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features[0].cpu().numpy()\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(text=None, images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features[0].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe2baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681c8c5b6e624e8ab285d183099c4fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77824b5adf334825ad993cf89adbefa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (120 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (120) must match the size of tensor b (77) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m test_df[\u001b[33m'\u001b[39m\u001b[33mimage_embedding\u001b[39m\u001b[33m'\u001b[39m] = test_df[\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m].progress_apply(get_image_embedding)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_df[\u001b[33m\"\u001b[39m\u001b[33mreport_embedding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreport_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_text_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test_df[\u001b[33m\"\u001b[39m\u001b[33mmetadata_embedding\u001b[39m\u001b[33m\"\u001b[39m] = test_df[\u001b[33m'\u001b[39m\u001b[33mmetadata_description\u001b[39m\u001b[33m'\u001b[39m].progress_apply(get_text_embedding)\n\u001b[32m      4\u001b[39m test_df.to_parquet(\u001b[33m'\u001b[39m\u001b[33mdata/test_df_with_embeddings_clip.parquet\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/tqdm/std.py:917\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[39m\u001b[34m(df, func, *args, **kwargs)\u001b[39m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    919\u001b[39m     t.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/tqdm/std.py:912\u001b[39m, in \u001b[36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    907\u001b[39m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[32m    908\u001b[39m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[32m    911\u001b[39m     t.update(n=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.total \u001b[38;5;129;01mor\u001b[39;00m t.n < t.total \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mget_text_embedding\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     12\u001b[39m inputs = processor(text=[text], images=\u001b[38;5;28;01mNone\u001b[39;00m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, padding=\u001b[38;5;28;01mTrue\u001b[39;00m).to(device)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     text_features = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     text_features = text_features / text_features.norm(dim=-\u001b[32m1\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m text_features[\u001b[32m0\u001b[39m].cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:1003\u001b[39m, in \u001b[36mCLIPModel.get_text_features\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    998\u001b[39m output_hidden_states = (\n\u001b[32m    999\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m   1000\u001b[39m )\n\u001b[32m   1001\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1003\u001b[39m text_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1012\u001b[39m pooled_output = text_outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1013\u001b[39m text_features = \u001b[38;5;28mself\u001b[39m.text_projection(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:699\u001b[39m, in \u001b[36mCLIPTextTransformer.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    696\u001b[39m input_shape = input_ids.size()\n\u001b[32m    697\u001b[39m input_ids = input_ids.view(-\u001b[32m1\u001b[39m, input_shape[-\u001b[32m1\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[38;5;66;03m# CLIP's text model uses causal mask, prepare it here.\u001b[39;00m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# https://github.com/openai/CLIP/blob/cfcffb90e69f37bf2ff1e988237a0fbe41f33c04/clip/model.py#L324\u001b[39;00m\n\u001b[32m    703\u001b[39m causal_attention_mask = _create_4d_causal_attention_mask(\n\u001b[32m    704\u001b[39m     input_shape, hidden_states.dtype, device=hidden_states.device\n\u001b[32m    705\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:227\u001b[39m, in \u001b[36mCLIPTextEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, position_ids, inputs_embeds)\u001b[39m\n\u001b[32m    224\u001b[39m     inputs_embeds = \u001b[38;5;28mself\u001b[39m.token_embedding(input_ids)\n\u001b[32m    226\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.position_embedding(position_ids)\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m embeddings = \u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (120) must match the size of tensor b (77) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "test_df['image_embedding'] = test_df['path'].progress_apply(get_image_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "611dcab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd2d86b6f2c4b98aea038d0f59fc33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df[\"report_embedding\"] = test_df['report_text'].progress_apply(get_text_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a250793f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b89293cb5fc47ceaf51691c5b7176a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df[\"metadata_embedding\"] = test_df['metadata_description'].progress_apply(get_text_embedding)\n",
    "test_df.to_parquet('data/test_df_with_embeddings_clip.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
