{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5823d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domino\n",
    "from domino import embed\n",
    "from domino._embed.encoder import Encoder\n",
    "from domino import explore, DominoSlicer\n",
    "# Standard library imports\n",
    "import meerkat as mk\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Clip model \n",
    "from open_clip import create_model_from_pretrained, get_tokenizer\n",
    "from PIL import Image\n",
    "import random\n",
    "from meerkat import DataPanel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas() \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from utils import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e8a73f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Finding\n",
       "1.0    75455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "# split the data into train and test sets by 0.8 and 0.2\n",
    "# train_df = data_df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "# test_df = data_df.drop(train_df.index).reset_index(drop=True)   \n",
    "# # Save the train and test DataFrames to CSV files\n",
    "# # train_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df.csv\", index=False)\n",
    "# # test_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df.csv\", index=False)\n",
    "# Load the train and test DataFrames\n",
    "\n",
    "# train_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df.csv\")\n",
    "# test_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df.csv\")\n",
    "\n",
    "data_df[\"No Finding\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340fe7fd",
   "metadata": {},
   "source": [
    "Train finding & cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c016e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3251480/2005903429.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_df[\"No Finding\"].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned on finding: (227827, 16)\n",
      " Cardiomegaly: Cardiomegaly\n",
      "1.0    35840\n",
      "0.0    12743\n",
      "Name: count, dtype: int64\n",
      " Cardiomegaly: Cardiomegaly\n",
      " 1.0    34884\n",
      " 0.0    12646\n",
      "-1.0     4740\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# All the No finding columns have been  set to 1 or 0\n",
    "# clean the data_df on finding\n",
    "# Fill null values in \"No Finding\" column with 0\n",
    "data_df[\"No Finding\"].fillna(0, inplace=True)\n",
    "data_df_cleaned_finding = data_df[data_df[\"No Finding\"].isin([1, 0])].reset_index(drop=True)\n",
    "#data_df_cleaned_finding = data_df_cleaned_finding[data_df_cleaned_finding[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "print(f\"Data cleaned on finding: {data_df_cleaned_finding.shape}\")\n",
    "# Split the data into train and test sets by 0.8 and 0.2\n",
    "train_df = data_df_cleaned_finding.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "train_df = train_df[train_df[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True).copy()\n",
    "test_df = data_df_cleaned_finding.drop(train_df.index).reset_index(drop=True)   \n",
    "# Save the train and test DataFrames to CSV files\n",
    "print(f\" Cardiomegaly: {train_df['Cardiomegaly'].value_counts()}\")\n",
    "print(f\" Cardiomegaly: {test_df['Cardiomegaly'].value_counts()}\")\n",
    "# flip the No Finding column to Finding column\n",
    "train_df['Finding'] = train_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# Save the files \n",
    "train_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_findings_cardio.csv\", index=False)\n",
    "#test_df.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_findings_cardio.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a0dc559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>Finding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10335334</td>\n",
       "      <td>56048989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13007347</td>\n",
       "      <td>51404713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16425412</td>\n",
       "      <td>58032996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15281216</td>\n",
       "      <td>59204145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17419409</td>\n",
       "      <td>54829080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0    10335334  56048989          1.0           0.0            NaN    0.0   \n",
       "1    13007347  51404713          NaN           0.0            NaN    NaN   \n",
       "2    16425412  58032996          1.0           0.0            NaN    NaN   \n",
       "3    15281216  59204145          1.0           1.0            NaN    NaN   \n",
       "4    17419409  54829080          NaN           0.0            NaN    0.0   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                         NaN       NaN          NaN           NaN   \n",
       "1                         NaN       NaN          NaN           NaN   \n",
       "2                         1.0       NaN          NaN           NaN   \n",
       "3                         NaN       NaN          NaN           1.0   \n",
       "4                         NaN       NaN          NaN           NaN   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0         0.0               NaN            NaN        0.0           NaN   \n",
       "1         1.0               0.0            NaN        NaN           0.0   \n",
       "2         0.0               NaN            NaN        0.0           NaN   \n",
       "3         0.0               1.0            NaN        NaN           NaN   \n",
       "4         1.0               0.0            NaN        0.0           NaN   \n",
       "\n",
       "   Support Devices  Finding  \n",
       "0              1.0        1  \n",
       "1              1.0        0  \n",
       "2              NaN        1  \n",
       "3              NaN        1  \n",
       "4              NaN        0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b84977",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_new = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/test_df_with_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf291054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3251480/363068135.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df_new['No Finding'].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_3251480/363068135.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df_new['Cardiomegaly'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned on finding: (7946, 40)\n"
     ]
    }
   ],
   "source": [
    "test_df_new.head()\n",
    "test_df_new['No Finding'].fillna(0, inplace=True)\n",
    "test_df_new = test_df_new[test_df_new[\"No Finding\"].isin([1, 0])].reset_index(drop=True)\n",
    "test_df_new['Cardiomegaly'].value_counts()\n",
    "#len(test_df_new)\n",
    "# fill all cardiomegaly values if not 1 than set to 0\n",
    "test_df_new['Cardiomegaly'].fillna(0, inplace=True)\n",
    "test_df_new = test_df_new[test_df_new[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "print(f\"Data cleaned on finding: {test_df_new.shape}\")\n",
    "# Save the test DataFrame to CSV file\n",
    "#test_df_new.to_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_findings_cardio.csv\", index=False)\n",
    "test_df_new['Finding'] = test_df_new['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "test_df_new.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_with_embeddings_cardio.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabf647",
   "metadata": {},
   "source": [
    "Train No Finding & View Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c77de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "data_df[\"No Finding\"].fillna(0)\n",
    "data_df_cleaned_finding = data_df[data_df[\"No Finding\"].isin([1, 0])].reset_index(drop=True)\n",
    "meta_df = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/meta_df_processed.parquet\")\n",
    "\n",
    "# Merge the data_df_cleaned_finding to meta_df_processed on \"subject_id\" and \"study_id\"\n",
    "data_meta_df = pd.merge(data_df_cleaned_finding, meta_df, on=[\"subject_id\", \"study_id\"], how=\"right\")\n",
    "data_meta_df['view_position_text'].value_counts()\n",
    "train_df = data_meta_df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "# drop all the rows with view_position_text as \"standard view'\n",
    "train_df = train_df[train_df[\"view_position_text\"] != \"standard view\"].reset_index(drop=True)\n",
    "train_df['Position'] = [0 if 'lateral' in x else 1 for x in train_df['view_position_text']]\n",
    "train_df['Position'].value_counts()\n",
    "train_df['Finding'] = train_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "train_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_position.parquet\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65d57ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'study_id', 'Atelectasis', 'Cardiomegaly',\n",
       "       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture',\n",
       "       'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
       "       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices',\n",
       "       'dicom_id', 'PerformedProcedureStepDescription', 'ViewPosition', 'Rows',\n",
       "       'Columns', 'StudyDate', 'StudyTime',\n",
       "       'ProcedureCodeSequence_CodeMeaning', 'ViewCodeSequence_CodeMeaning',\n",
       "       'PatientOrientationCodeSequence_CodeMeaning', 'id', 'exam_type_text',\n",
       "       'view_position_text', 'patient_orientation_text', 'image_quality_text',\n",
       "       'study_time_text', 'metadata_description', 'Position', 'Finding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04a30dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>PerformedProcedureStepDescription</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>ProcedureCodeSequence_CodeMeaning</th>\n",
       "      <th>ViewCodeSequence_CodeMeaning</th>\n",
       "      <th>PatientOrientationCodeSequence_CodeMeaning</th>\n",
       "      <th>id</th>\n",
       "      <th>exam_type_text</th>\n",
       "      <th>view_position_text</th>\n",
       "      <th>patient_orientation_text</th>\n",
       "      <th>image_quality_text</th>\n",
       "      <th>study_time_text</th>\n",
       "      <th>metadata_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 50414267]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 50414267]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 53189527]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>[10000032, 53189527]</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>2705</td>\n",
       "      <td>2539</td>\n",
       "      <td>21800723</td>\n",
       "      <td>80556.875</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>None</td>\n",
       "      <td>[10000032, 53911762]</td>\n",
       "      <td>bedside portable chest radiography</td>\n",
       "      <td>anterior-posterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>standard resolution</td>\n",
       "      <td>in July 2180 during night hours</td>\n",
       "      <td>Patient underwent bedside portable chest radio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  subject_id  study_id  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014    10000032  50414267   \n",
       "1  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962    10000032  50414267   \n",
       "2  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab    10000032  53189527   \n",
       "3  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c    10000032  53189527   \n",
       "4  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714    10000032  53911762   \n",
       "\n",
       "  PerformedProcedureStepDescription ViewPosition  Rows  Columns  StudyDate  \\\n",
       "0                CHEST (PA AND LAT)           PA  3056     2544   21800506   \n",
       "1                CHEST (PA AND LAT)      LATERAL  3056     2544   21800506   \n",
       "2                CHEST (PA AND LAT)           PA  3056     2544   21800626   \n",
       "3                CHEST (PA AND LAT)      LATERAL  3056     2544   21800626   \n",
       "4               CHEST (PORTABLE AP)           AP  2705     2539   21800723   \n",
       "\n",
       "    StudyTime ProcedureCodeSequence_CodeMeaning ViewCodeSequence_CodeMeaning  \\\n",
       "0  213014.531                CHEST (PA AND LAT)             postero-anterior   \n",
       "1  213014.531                CHEST (PA AND LAT)                      lateral   \n",
       "2  165500.312                CHEST (PA AND LAT)             postero-anterior   \n",
       "3  165500.312                CHEST (PA AND LAT)                      lateral   \n",
       "4   80556.875               CHEST (PORTABLE AP)             antero-posterior   \n",
       "\n",
       "  PatientOrientationCodeSequence_CodeMeaning                    id  \\\n",
       "0                                      Erect  [10000032, 50414267]   \n",
       "1                                      Erect  [10000032, 50414267]   \n",
       "2                                      Erect  [10000032, 53189527]   \n",
       "3                                      Erect  [10000032, 53189527]   \n",
       "4                                       None  [10000032, 53911762]   \n",
       "\n",
       "                       exam_type_text       view_position_text  \\\n",
       "0                   chest radiography  posterior-anterior view   \n",
       "1                   chest radiography             lateral view   \n",
       "2                   chest radiography  posterior-anterior view   \n",
       "3                   chest radiography             lateral view   \n",
       "4  bedside portable chest radiography  anterior-posterior view   \n",
       "\n",
       "  patient_orientation_text   image_quality_text  \\\n",
       "0         upright position      high-resolution   \n",
       "1         upright position      high-resolution   \n",
       "2         upright position      high-resolution   \n",
       "3         upright position      high-resolution   \n",
       "4         upright position  standard resolution   \n",
       "\n",
       "                       study_time_text  \\\n",
       "0     in May 2180 during evening hours   \n",
       "1     in May 2180 during evening hours   \n",
       "2  in June 2180 during afternoon hours   \n",
       "3  in June 2180 during afternoon hours   \n",
       "4      in July 2180 during night hours   \n",
       "\n",
       "                                metadata_description  \n",
       "0  Patient underwent chest radiography in May 218...  \n",
       "1  Patient underwent chest radiography in May 218...  \n",
       "2  Patient underwent chest radiography in June 21...  \n",
       "3  Patient underwent chest radiography in June 21...  \n",
       "4  Patient underwent bedside portable chest radio...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6303ea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'study_id', 'Atelectasis', 'Cardiomegaly',\n",
      "       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture',\n",
      "       'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
      "       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices',\n",
      "       'predicted', 'true', 'id_x', 'path', 'dicom_id_x',\n",
      "       'PerformedProcedureStepDescription_x', 'ViewPosition_x', 'Rows_x',\n",
      "       'Columns_x', 'StudyDate_x', 'StudyTime_x',\n",
      "       'ProcedureCodeSequence_CodeMeaning_x', 'ViewCodeSequence_CodeMeaning_x',\n",
      "       'PatientOrientationCodeSequence_CodeMeaning_x', 'exam_type_text_x',\n",
      "       'view_position_text_x', 'patient_orientation_text_x',\n",
      "       'image_quality_text_x', 'study_time_text_x', 'metadata_description_x',\n",
      "       'report_text', 'image_embedding', 'report_embedding',\n",
      "       'metadata_embedding', 'dicom_id_y',\n",
      "       'PerformedProcedureStepDescription_y', 'ViewPosition_y', 'Rows_y',\n",
      "       'Columns_y', 'StudyDate_y', 'StudyTime_y',\n",
      "       'ProcedureCodeSequence_CodeMeaning_y', 'ViewCodeSequence_CodeMeaning_y',\n",
      "       'PatientOrientationCodeSequence_CodeMeaning_y', 'id_y',\n",
      "       'exam_type_text_y', 'view_position_text_y',\n",
      "       'patient_orientation_text_y', 'image_quality_text_y',\n",
      "       'study_time_text_y', 'metadata_description_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_meta_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c270b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position\n",
      "1    7392\n",
      "0    1005\n",
      "Name: count, dtype: int64\n",
      "Finding\n",
      "1    7523\n",
      "0     874\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_df_new = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/test_df_with_embeddings.parquet\")\n",
    "\n",
    "\n",
    "test_df_new['No Finding'] = test_df_new['No Finding'].fillna(0)\n",
    "test_df_new = test_df_new[test_df_new['No Finding'].isin([0, 1])].reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "\n",
    "test_meta_df = test_df_new.copy()\n",
    "\n",
    "\n",
    "test_meta_df['Finding'] = test_meta_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "test_meta_df['Position'] = [0 if 'lateral' in x else 1 for x in test_meta_df['view_position_text']]\n",
    "\n",
    "print(test_meta_df['Position'].value_counts())\n",
    "print(test_meta_df['Finding'].value_counts())\n",
    "\n",
    "\n",
    "test_meta_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_position.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5723ae72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'study_id', 'Atelectasis', 'Cardiomegaly',\n",
       "       'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture',\n",
       "       'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
       "       'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices',\n",
       "       'predicted', 'true', 'id_x', 'path', 'dicom_id_x',\n",
       "       'PerformedProcedureStepDescription_x', 'ViewPosition_x', 'Rows_x',\n",
       "       'Columns_x', 'StudyDate_x', 'StudyTime_x',\n",
       "       'ProcedureCodeSequence_CodeMeaning_x', 'ViewCodeSequence_CodeMeaning_x',\n",
       "       'PatientOrientationCodeSequence_CodeMeaning_x', 'exam_type_text_x',\n",
       "       'view_position_text_x', 'patient_orientation_text_x',\n",
       "       'image_quality_text_x', 'study_time_text_x', 'metadata_description_x',\n",
       "       'report_text', 'image_embedding', 'report_embedding',\n",
       "       'metadata_embedding', 'dicom_id_y',\n",
       "       'PerformedProcedureStepDescription_y', 'ViewPosition_y', 'Rows_y',\n",
       "       'Columns_y', 'StudyDate_y', 'StudyTime_y',\n",
       "       'ProcedureCodeSequence_CodeMeaning_y', 'ViewCodeSequence_CodeMeaning_y',\n",
       "       'PatientOrientationCodeSequence_CodeMeaning_y', 'id_y',\n",
       "       'exam_type_text_y', 'view_position_text_y',\n",
       "       'patient_orientation_text_y', 'image_quality_text_y',\n",
       "       'study_time_text_y', 'metadata_description_y', 'Position', 'Finding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_meta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20907f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Position\n",
       "1    64965\n",
       "0    45001\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eafdae8",
   "metadata": {},
   "source": [
    "### Metadata Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c3f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "meta_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-metadata.csv\")\n",
    "meta_df['id'] = list(zip(meta_df['subject_id'].astype(str), \n",
    "                            meta_df['study_id'].astype(str))) \n",
    "# Convert the information to the text format \n",
    "meta_df_processed = convert_medical_metadata_to_text(meta_df)  \n",
    "meta_df_processed.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/meta_df_processed.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26620a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>PerformedProcedureStepDescription</th>\n",
       "      <th>ViewPosition</th>\n",
       "      <th>Rows</th>\n",
       "      <th>Columns</th>\n",
       "      <th>StudyDate</th>\n",
       "      <th>StudyTime</th>\n",
       "      <th>ProcedureCodeSequence_CodeMeaning</th>\n",
       "      <th>ViewCodeSequence_CodeMeaning</th>\n",
       "      <th>PatientOrientationCodeSequence_CodeMeaning</th>\n",
       "      <th>id</th>\n",
       "      <th>exam_type_text</th>\n",
       "      <th>view_position_text</th>\n",
       "      <th>patient_orientation_text</th>\n",
       "      <th>image_quality_text</th>\n",
       "      <th>study_time_text</th>\n",
       "      <th>metadata_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02aa804e-bde0afdd-112c0b34-7bc16630-4e384014</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 50414267)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962</td>\n",
       "      <td>10000032</td>\n",
       "      <td>50414267</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800506</td>\n",
       "      <td>213014.531</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 50414267)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in May 2180 during evening hours</td>\n",
       "      <td>Patient underwent chest radiography in May 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>PA</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>postero-anterior</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 53189527)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>posterior-anterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53189527</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>LATERAL</td>\n",
       "      <td>3056</td>\n",
       "      <td>2544</td>\n",
       "      <td>21800626</td>\n",
       "      <td>165500.312</td>\n",
       "      <td>CHEST (PA AND LAT)</td>\n",
       "      <td>lateral</td>\n",
       "      <td>Erect</td>\n",
       "      <td>(10000032, 53189527)</td>\n",
       "      <td>chest radiography</td>\n",
       "      <td>lateral view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>high-resolution</td>\n",
       "      <td>in June 2180 during afternoon hours</td>\n",
       "      <td>Patient underwent chest radiography in June 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714</td>\n",
       "      <td>10000032</td>\n",
       "      <td>53911762</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>AP</td>\n",
       "      <td>2705</td>\n",
       "      <td>2539</td>\n",
       "      <td>21800723</td>\n",
       "      <td>80556.875</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>antero-posterior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(10000032, 53911762)</td>\n",
       "      <td>bedside portable chest radiography</td>\n",
       "      <td>anterior-posterior view</td>\n",
       "      <td>upright position</td>\n",
       "      <td>standard resolution</td>\n",
       "      <td>in July 2180 during night hours</td>\n",
       "      <td>Patient underwent bedside portable chest radio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       dicom_id  subject_id  study_id  \\\n",
       "0  02aa804e-bde0afdd-112c0b34-7bc16630-4e384014    10000032  50414267   \n",
       "1  174413ec-4ec4c1f7-34ea26b7-c5f994f8-79ef1962    10000032  50414267   \n",
       "2  2a2277a9-b0ded155-c0de8eb9-c124d10e-82c5caab    10000032  53189527   \n",
       "3  e084de3b-be89b11e-20fe3f9f-9c8d8dfe-4cfd202c    10000032  53189527   \n",
       "4  68b5c4b1-227d0485-9cc38c3f-7b84ab51-4b472714    10000032  53911762   \n",
       "\n",
       "  PerformedProcedureStepDescription ViewPosition  Rows  Columns  StudyDate  \\\n",
       "0                CHEST (PA AND LAT)           PA  3056     2544   21800506   \n",
       "1                CHEST (PA AND LAT)      LATERAL  3056     2544   21800506   \n",
       "2                CHEST (PA AND LAT)           PA  3056     2544   21800626   \n",
       "3                CHEST (PA AND LAT)      LATERAL  3056     2544   21800626   \n",
       "4               CHEST (PORTABLE AP)           AP  2705     2539   21800723   \n",
       "\n",
       "    StudyTime ProcedureCodeSequence_CodeMeaning ViewCodeSequence_CodeMeaning  \\\n",
       "0  213014.531                CHEST (PA AND LAT)             postero-anterior   \n",
       "1  213014.531                CHEST (PA AND LAT)                      lateral   \n",
       "2  165500.312                CHEST (PA AND LAT)             postero-anterior   \n",
       "3  165500.312                CHEST (PA AND LAT)                      lateral   \n",
       "4   80556.875               CHEST (PORTABLE AP)             antero-posterior   \n",
       "\n",
       "  PatientOrientationCodeSequence_CodeMeaning                    id  \\\n",
       "0                                      Erect  (10000032, 50414267)   \n",
       "1                                      Erect  (10000032, 50414267)   \n",
       "2                                      Erect  (10000032, 53189527)   \n",
       "3                                      Erect  (10000032, 53189527)   \n",
       "4                                        NaN  (10000032, 53911762)   \n",
       "\n",
       "                       exam_type_text       view_position_text  \\\n",
       "0                   chest radiography  posterior-anterior view   \n",
       "1                   chest radiography             lateral view   \n",
       "2                   chest radiography  posterior-anterior view   \n",
       "3                   chest radiography             lateral view   \n",
       "4  bedside portable chest radiography  anterior-posterior view   \n",
       "\n",
       "  patient_orientation_text   image_quality_text  \\\n",
       "0         upright position      high-resolution   \n",
       "1         upright position      high-resolution   \n",
       "2         upright position      high-resolution   \n",
       "3         upright position      high-resolution   \n",
       "4         upright position  standard resolution   \n",
       "\n",
       "                       study_time_text  \\\n",
       "0     in May 2180 during evening hours   \n",
       "1     in May 2180 during evening hours   \n",
       "2  in June 2180 during afternoon hours   \n",
       "3  in June 2180 during afternoon hours   \n",
       "4      in July 2180 during night hours   \n",
       "\n",
       "                                metadata_description  \n",
       "0  Patient underwent chest radiography in May 218...  \n",
       "1  Patient underwent chest radiography in May 218...  \n",
       "2  Patient underwent chest radiography in June 21...  \n",
       "3  Patient underwent chest radiography in June 21...  \n",
       "4  Patient underwent bedside portable chest radio...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a176e8",
   "metadata": {},
   "source": [
    "### Metadata Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99db94e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "view_position_text\n",
       "anterior-posterior view        147173\n",
       "lateral view                   117986\n",
       "posterior-anterior view         96161\n",
       "standard view                   15784\n",
       "left anterior oblique view          3\n",
       "right anterior oblique view         3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df_processed.head()\n",
    "meta_df_processed[\"view_position_text\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a9be0",
   "metadata": {},
   "source": [
    "### Test Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8504d1a4",
   "metadata": {},
   "source": [
    "Report Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2dd75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10543/10543 [00:12<00:00, 843.08it/s] \n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "REPORTS_DIR = \"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/files/mimic_reports/\"\n",
    "\n",
    "def read_mimic_report(subject_id, study_id):\n",
    "    subject_dir = f\"p{str(subject_id)[:2]}\"\n",
    "    subject_full = f\"p{subject_id}\"\n",
    "    report_file = f\"s{study_id}.txt\"\n",
    "    file_path = os.path.join(REPORTS_DIR, 'files', subject_dir, subject_full, report_file)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "\n",
    "test_df['report_text'] = test_df.progress_apply(\n",
    "    lambda row: read_mimic_report(row['subject_id'], row['study_id']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aadd9324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing paths: 1356\n",
      "Number of missing metadata descriptions: 0\n",
      "length of test_df: 9187\n"
     ]
    }
   ],
   "source": [
    "# import the path file\n",
    "path = pickle.load(open('file_map_cache_complete.pkl', 'rb'))\n",
    "\n",
    "# convert the path to a DataFrame\n",
    "test_df['id'] = list(zip(test_df['subject_id'].astype(str), \n",
    "                         test_df['study_id'].astype(str)))\n",
    "path_images = [k[0] for k in path.values()]\n",
    "path_df = pd.DataFrame({\"id\": list(path.keys()), \"path\": path_images})\n",
    "test_df = pd.merge(test_df, path_df, on='id', how='left')\n",
    "\n",
    "# find the id without a path\n",
    "missing_paths = test_df[test_df['path'].isnull()]['id'].tolist()\n",
    "print(f\"Number of missing paths: {len(missing_paths)}\")\n",
    "\n",
    "\n",
    "test_df = test_df[test_df['path'].notnull()].copy()\n",
    "\n",
    "# extract dicom_id from path safely\n",
    "test_df[\"dicom_id\"] = test_df[\"path\"].apply(lambda x: os.path.basename(x).split('.')[0])\n",
    "\n",
    "# merge the test_df with the metadata\n",
    "test_df = pd.merge(test_df, meta_df_processed, on='dicom_id', how='left')\n",
    "\n",
    "# find the id without a metadata description\n",
    "missing_metadata = test_df[test_df['metadata_description'].isnull()]['dicom_id'].tolist()\n",
    "print(f\"Number of missing metadata descriptions: {len(missing_metadata)}\")\n",
    "\n",
    "print(\"length of test_df:\", len(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687a09b",
   "metadata": {},
   "source": [
    "### Extract Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65040ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embedding for the images and report text\n",
    "model, preprocess = create_model_from_pretrained(\n",
    "    'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
    ")\n",
    "tokenizer = get_tokenizer(\n",
    "    'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device).eval()\n",
    "\n",
    "# define Transform which resize the image to 224x224 and normalize it\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(           \n",
    "        mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "        std=[0.26862954, 0.26130258, 0.27577711]\n",
    "    )\n",
    "])\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    tokenized = tokenizer([text]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(tokenized)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)  \n",
    "    return text_features[0].cpu().numpy() # Add batch dimension for consistency\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "\n",
    "    image_tensor = preprocess(image).unsqueeze(0).to(device) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        image_features = model.encode_image(image_tensor)\n",
    "\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    return image_features[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['image_embedding'] = test_df['path'].progress_apply(get_image_embedding)\n",
    "test_df[\"report_embedding\"] = test_df['report_text'].progress_apply(get_text_embedding)\n",
    "test_df[\"metadata_embedding\"] = test_df['metadata_description'].progress_apply(get_text_embedding)\n",
    "test_df.to_parquet('test_df_with_embeddings_v2.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e894d568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15517908</td>\n",
       "      <td>54944476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14997223</td>\n",
       "      <td>56919551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15831913</td>\n",
       "      <td>55952386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18994929</td>\n",
       "      <td>53818785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12868814</td>\n",
       "      <td>58575191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42166</th>\n",
       "      <td>14325424</td>\n",
       "      <td>58251915</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42167</th>\n",
       "      <td>13295971</td>\n",
       "      <td>50868944</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42168</th>\n",
       "      <td>18527164</td>\n",
       "      <td>50617229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42169</th>\n",
       "      <td>16898052</td>\n",
       "      <td>54026371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42170</th>\n",
       "      <td>15247151</td>\n",
       "      <td>59516241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42171 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
       "0        15517908  54944476          1.0           1.0            NaN   -1.0   \n",
       "1        14997223  56919551          1.0           1.0            NaN    NaN   \n",
       "2        15831913  55952386          NaN           NaN            NaN    NaN   \n",
       "3        18994929  53818785          1.0           NaN            NaN    NaN   \n",
       "4        12868814  58575191          NaN           1.0            NaN   -1.0   \n",
       "...           ...       ...          ...           ...            ...    ...   \n",
       "42166    14325424  58251915          NaN           NaN            1.0    NaN   \n",
       "42167    13295971  50868944          1.0           NaN            NaN    0.0   \n",
       "42168    18527164  50617229          1.0           NaN            NaN    NaN   \n",
       "42169    16898052  54026371          1.0           NaN            NaN    NaN   \n",
       "42170    15247151  59516241          1.0           0.0            NaN    NaN   \n",
       "\n",
       "       Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                             NaN       1.0          NaN           1.0   \n",
       "1                            -1.0       NaN          NaN           NaN   \n",
       "2                             NaN       NaN          NaN           NaN   \n",
       "3                             NaN       NaN          NaN           NaN   \n",
       "4                             NaN       NaN          NaN           1.0   \n",
       "...                           ...       ...          ...           ...   \n",
       "42166                        -1.0       NaN          NaN           1.0   \n",
       "42167                         NaN       NaN          NaN           NaN   \n",
       "42168                         NaN       NaN          NaN           1.0   \n",
       "42169                         NaN       NaN          NaN           NaN   \n",
       "42170                         NaN       NaN          NaN           NaN   \n",
       "\n",
       "       No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0             NaN               1.0            NaN        NaN           0.0   \n",
       "1             NaN               1.0            NaN        NaN           0.0   \n",
       "2             NaN               1.0            NaN        NaN           0.0   \n",
       "3             NaN               NaN            NaN        NaN           0.0   \n",
       "4             NaN               1.0            NaN        NaN           1.0   \n",
       "...           ...               ...            ...        ...           ...   \n",
       "42166         NaN               1.0            NaN        NaN           1.0   \n",
       "42167         NaN               0.0            NaN        NaN           0.0   \n",
       "42168         NaN               1.0            NaN        NaN           0.0   \n",
       "42169         NaN               NaN            NaN        NaN           0.0   \n",
       "42170         NaN               NaN            NaN        NaN           0.0   \n",
       "\n",
       "       Support Devices  \n",
       "0                  NaN  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "...                ...  \n",
       "42166              1.0  \n",
       "42167              1.0  \n",
       "42168              1.0  \n",
       "42169              1.0  \n",
       "42170              NaN  \n",
       "\n",
       "[42171 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d2e57",
   "metadata": {},
   "source": [
    "### Train data set for meta classifiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df = train_df.merge(\n",
    "    meta_df_processed[['subject_id', 'study_id', 'exam_type_text']],\n",
    "    on=['subject_id', 'study_id'],\n",
    "    how='left'\n",
    ")\n",
    "train_meta_df['is_portable'] = train_meta_df['exam_type_text']\\\n",
    "    .str.contains('portable', case=False, na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2d0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 1,0\n",
    "train_meta_df['is_portable'] = train_meta_df['is_portable'].astype(int)\n",
    "\n",
    "# test set \n",
    "test_df = pd.read_parquet('test_df_with_embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6371055",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta_df = test_df.copy()\n",
    "test_meta_df['is_portable'] = test_meta_df['exam_type_text']\\\n",
    "    .str.contains('portable', case=False, na=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f060dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train meta DataFrame shape: (25239, 18)\n",
      "Cardiomegaly\n",
      "1.0    16597\n",
      "0.0     8642\n",
      "Name: count, dtype: int64\n",
      "Test meta DataFrame shape: (3701, 41)\n",
      "Cardiomegaly\n",
      "1.0    2505\n",
      "0.0    1196\n",
      "Name: count, dtype: int64\n",
      "Train meta DataFrame is_portable value counts:\n",
      "is_portable\n",
      "1    16016\n",
      "0     9223\n",
      "Name: count, dtype: int64\n",
      "Test meta DataFrame is_portable value counts:\n",
      "is_portable\n",
      "True     2835\n",
      "False     866\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_meta_df = train_meta_df[train_meta_df['Cardiomegaly'].isin([0, 1])]\n",
    "print(\"Train meta DataFrame shape:\", train_meta_df.shape)\n",
    "# value counts for Cardiomegaly\n",
    "print(train_meta_df['Cardiomegaly'].value_counts())\n",
    "test_meta_df = test_meta_df[test_meta_df['Cardiomegaly'].isin([0, 1])]\n",
    "print(\"Test meta DataFrame shape:\", test_meta_df.shape)\n",
    "# value counts for Cardiomegaly\n",
    "print(test_meta_df['Cardiomegaly'].value_counts())\n",
    "# for portable value counts\n",
    "print(\"Train meta DataFrame is_portable value counts:\")\n",
    "print(train_meta_df['is_portable'].value_counts())\n",
    "print(\"Test meta DataFrame is_portable value counts:\")\n",
    "print(test_meta_df['is_portable'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a721e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test dataframes with meta embeddings \n",
    "train_meta_df.to_parquet('train_meta_df_with_embeddings.parquet', index=False)\n",
    "test_meta_df.to_parquet('test_meta_df_with_embeddings.parquet', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edc36c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1614328/2254601363.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_df[\"Cardiomegaly\"].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cardiomegaly\n",
       "0.0    233213\n",
       "1.0     49289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/physionet.org/files/mimic-cxr-jpg/2.1.0/mimic-cxr-2.0.0-chexpert.csv\")\n",
    "#data_df[\"No Finding\"].fillna(0)\n",
    "data_df[\"Cardiomegaly\"].fillna(0, inplace=True)\n",
    "data_df_cleaned_finding = data_df[data_df[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "meta_df = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/meta_df_processed.parquet\")\n",
    "\n",
    "# Merge the data_df_cleaned_finding to meta_df_processed on \"subject_id\" and \"study_id\"\n",
    "data_meta_df = pd.merge(data_df_cleaned_finding, meta_df, on=[\"subject_id\", \"study_id\"], how=\"right\")\n",
    "data_meta_df['view_position_text'].value_counts()\n",
    "train_df = data_meta_df.sample(frac=0.8, random_state=42).reset_index(drop=True)\n",
    "# drop all the rows with view_position_text as \"standard view'\n",
    "train_df = train_df[train_df[\"view_position_text\"] != \"standard view\"].reset_index(drop=True)\n",
    "train_df['Position'] = [0 if 'lateral' in x else 1 for x in train_df['view_position_text']]\n",
    "train_df['Cardiomegaly'].value_counts()\n",
    "\n",
    "#train_df['Finding'] = train_df['No Finding'].apply(lambda x: 0 if x == 1 else 1)\n",
    "#train_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_position.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31f8c93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81978</td>\n",
       "      <td>11157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151235</td>\n",
       "      <td>38132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cardiomegaly     0.0    1.0\n",
       "Position                   \n",
       "0              81978  11157\n",
       "1             151235  38132"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_results.groupby(['Position', 'true']).size().unstack(fill_value=0)\n",
    "train_df.groupby(['Position', 'Cardiomegaly']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c56df23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train and test dataframes with meta embeddings\n",
    "test_df = pd.read_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_position.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4982865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1614328/3084683551.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Cardiomegaly'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4709</td>\n",
       "      <td>2289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cardiomegaly   0.0   1.0\n",
       "Position                \n",
       "0              732   216\n",
       "1             4709  2289"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Cardiomegaly'].fillna(0, inplace=True)\n",
    "test_df = test_df[test_df[\"Cardiomegaly\"].isin([1, 0])].reset_index(drop=True)\n",
    "test_df.groupby(['Position', 'Cardiomegaly']).size().unstack(fill_value=0)\n",
    "# Save the test DataFrame to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "484acaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes with embeddings\n",
    "test_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/test_df_with_embeddings_cardio_position.parquet\", index=False)\n",
    "train_df.to_parquet(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df_cardio_position.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b0049",
   "metadata": {},
   "source": [
    "### Create the embedding use clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e035ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test_df_with_embeddings.parquet')\n",
    "train_df = pd.read_csv(\"/vol/bitbucket/yl28218/thesis/mimic_cxr_exp/data/train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7359982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/yl28218/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "def get_text_embedding(text):\n",
    "    inputs = processor(text=[text], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.get_text_features(**inputs)\n",
    "        text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    return text_features[0].cpu().numpy()\n",
    "\n",
    "def get_image_embedding(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(text=None, images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.get_image_features(**inputs)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    return image_features[0].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64526bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['image_embedding'] = test_df['path'].progress_apply(get_image_embedding)\n",
    "test_df[\"report_embedding\"] = test_df['report_text'].progress_apply(get_text_embedding)\n",
    "test_df[\"metadata_embedding\"] = test_df['metadata_description'].progress_apply(get_text_embedding)\n",
    "test_df.to_parquet('data/test_df_with_embeddings_clip.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194a66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
